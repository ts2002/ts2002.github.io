{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4XtQpK_fLoEJ"
      },
      "outputs": [],
      "source": [
        "# For data handling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# For linear models\n",
        "from sklearn import linear_model\n",
        "# Weak learners for Gradient Boosting\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# Scaler hyperparams\n",
        "from sklearn.preprocessing import StandardScaler, QuantileTransformer, MinMaxScaler, PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split as tts, KFold, GridSearchCV\n",
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from scipy.spatial.distance import cdist\n",
        "import collections\n",
        "import warnings\n",
        "\n",
        "\n",
        "# testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "# For making SKlearn compliant funcs\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
        "\n",
        "# Extreme gradients\n",
        "import xgboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "DwgypQqtLzur"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1:"
      ],
      "metadata": {
        "id": "qpflHgywL4XB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Boosting w/ Locally Weighted Regression Class"
      ],
      "metadata": {
        "id": "P2Uusu4EMJzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Kernel Types, Weight function"
      ],
      "metadata": {
        "id": "6pxGV4f9MDI4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Gaussian(x):\n",
        "  return np.where(np.abs(x)>4,0,1/(np.sqrt(2*np.pi))*np.exp(-1/2*x**2))\n",
        "def Tricubic(x):\n",
        "  return np.where(np.abs(x)>1,0,(1-np.abs(x)**3)**3)\n",
        "def Epanechnikov(x):\n",
        "  return np.where(np.abs(x)>1,0,3/4*(1-np.abs(x)**2))\n",
        "def Quartic(x):\n",
        "  return np.where(np.abs(x)>1,0,15/16*(1-np.abs(x)**2)**2)"
      ],
      "metadata": {
        "id": "09KF8CioMRWA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weight_function(u,v,kern=Gaussian,tau=0.5):\n",
        "    return kern(cdist(u, v, metric='euclidean')/(2*tau))"
      ],
      "metadata": {
        "id": "CRmwAXgGMSG7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOWESS class w/o triangularization from lecture"
      ],
      "metadata": {
        "id": "JHjlJm1mMTdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lowess class from lecture\n",
        "\n",
        "class Lowess:\n",
        "    def __init__(self, kernel = Gaussian, tau=0.05):\n",
        "        self.kernel = kernel\n",
        "        self.tau = tau\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        kernel = self.kernel\n",
        "        tau = self.tau\n",
        "        self.xtrain_ = x\n",
        "        self.yhat_ = y\n",
        "\n",
        "    def predict(self, x_new):\n",
        "        check_is_fitted(self)\n",
        "        x = self.xtrain_\n",
        "        y = self.yhat_\n",
        "        lm = linear_model.Ridge(alpha=0.001)\n",
        "        w = weight_function(x,x_new,self.kernel,self.tau)\n",
        "\n",
        "        if np.isscalar(x_new):\n",
        "          lm.fit(np.diag(w)@(x.reshape(-1,1)),np.diag(w)@(y.reshape(-1,1)))\n",
        "          yest = lm.predict([[x_new]])[0][0]\n",
        "        else:\n",
        "          n = len(x_new)\n",
        "          yest_test = np.zeros(n)\n",
        "          for i in range(n):\n",
        "            lm.fit(np.diag(w[:,i])@x,np.diag(w[:,i])@y)\n",
        "            yest_test[i] = lm.predict(x_new[i].reshape(1,-1))\n",
        "        return yest_test"
      ],
      "metadata": {
        "id": "w7j-4KIsMcdz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting Data (concrete dataset)"
      ],
      "metadata": {
        "id": "wqBqbK7_Mmxq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/ML2023/data/concrete.csv')"
      ],
      "metadata": {
        "id": "TMWn89JTMni7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = data.loc[:,'cement':'age'].values\n",
        "y = data['strength'].values"
      ],
      "metadata": {
        "id": "IcjbiUdnMrg1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Boosting Class"
      ],
      "metadata": {
        "id": "NVB8orFlNKM1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GradientBoosting_LOWESS:\n",
        "  def __init__(self, x, y, scaler=StandardScaler(), num_steps=1, n_estimators=150, max_depth=7, tau=0.9):\n",
        "    self.x_train = scaler.fit_transform(x)\n",
        "    self.y_train = y\n",
        "    self.fitted = False\n",
        "    self._scaler = scaler\n",
        "    self._num_steps = num_steps\n",
        "    self._n_estimators = n_estimators\n",
        "    self._max_depth = max_depth\n",
        "    self._tau = tau\n",
        "\n",
        "  def is_fitted(self):\n",
        "    return self.fitted\n",
        "\n",
        "  def fit(self, x, y):\n",
        "\n",
        "    x_train = self.x_train\n",
        "    y_train = self.y_train\n",
        "\n",
        "    # Will hold the number of weak learners per the number of boosting steps\n",
        "    self._weak_learners = []\n",
        "    # Strong learner (Lowess)\n",
        "    self.regressor = Lowess(kernel=Gaussian, tau=self._tau)\n",
        "    self.regressor.fit(x_train, y_train)\n",
        "    yhat_train = self.regressor.predict(x_train)\n",
        "    residuals_regressor = y_train.flatten() - yhat_train\n",
        "    # Creating the weak learners\n",
        "    for i in range(self._num_steps):\n",
        "      self._weak_learners.append(RandomForestRegressor(n_estimators=self._n_estimators, max_depth=self._max_depth))\n",
        "\n",
        "    # For each weak learner, train it on the residuals of the previous model\n",
        "    cur_residuals = residuals_regressor\n",
        "    for weak_learner in self._weak_learners:\n",
        "      # Train the current weak learner on the current residuals\n",
        "      weak_learner.fit(x_train, cur_residuals)\n",
        "      # Get the new residuals to train the next weak learner on\n",
        "      cur_yhat_train = weak_learner.predict(x_train)\n",
        "      cur_residuals = cur_residuals - cur_yhat_train\n",
        "\n",
        "  def predict(self, x_new):\n",
        "    # Transform new x w/ scaler\n",
        "    x_new = self._scaler.fit_transform(x_new)\n",
        "    # Get strong model predictions\n",
        "    yhat_regressor = self.regressor.predict(x_new)\n",
        "\n",
        "    # For each weak learner, append to their predictions to the result\n",
        "    weak_residuals = []\n",
        "    for weak_learner in self._weak_learners:\n",
        "      weak_residuals.append(weak_learner.predict(x_new))\n",
        "\n",
        "    prediction = yhat_regressor\n",
        "    for item in weak_residuals:\n",
        "      prediction += item\n",
        "\n",
        "\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "v8Oiw46qNM2C"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Showing results of Xtreme Boosting"
      ],
      "metadata": {
        "id": "Vm0fBV-nNxLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse_xtreme = []\n",
        "scaler = StandardScaler()\n",
        "kf = KFold(n_splits=10,shuffle=True,random_state=1234)\n",
        "\n",
        "for idxtrain, idxtest in kf.split(x):\n",
        "  xtrain = x[idxtrain]\n",
        "  ytrain = y[idxtrain]\n",
        "  ytest = y[idxtest]\n",
        "  xtest = x[idxtest]\n",
        "  xtrain = scaler.fit_transform(xtrain)\n",
        "  xtest = scaler.transform(xtest)\n",
        "\n",
        "  model_xgboost = xgboost.XGBRFRegressor(n_estimators=200,max_depth=7)\n",
        "\n",
        "  model_xgboost.fit(xtrain, ytrain)\n",
        "\n",
        "  mse_xtreme.append(mse(ytest,model_xgboost.predict(xtest)))\n",
        "\n",
        "print('The Cross-validated Mean Squared Error for Extreme Gradient Boosting is : '+str(np.mean(mse_xtreme)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iwIhEi6Nyt8",
        "outputId": "35cdd3ae-4e62-41fd-eb9b-a172dca0e65b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Cross-validated Mean Squared Error for Extreme Gradient Boosting is : 31.453653856769517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Showing results of my tuned Gradient Booster Class"
      ],
      "metadata": {
        "id": "-eUL-GX9N8rz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I found these parameters after doing KFold tuning with the max_depth, number of steps, number of estimators, scaler type (and number of quantiles for Quantile Transformer) and tau value."
      ],
      "metadata": {
        "id": "3uwKmhOxOG6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse_gd = []\n",
        "kf = KFold(n_splits=10,shuffle=True,random_state=1234)\n",
        "\n",
        "\n",
        "hyperparams = dict()\n",
        "mse_gd = []\n",
        "for idxtrain, idxtest in kf.split(x):\n",
        "  xtrain = x[idxtrain]\n",
        "  ytrain = y[idxtrain]\n",
        "  ytest = y[idxtest]\n",
        "  xtest = x[idxtest]\n",
        "\n",
        "  model = GradientBoosting_LOWESS(xtrain, ytrain, max_depth=7, num_steps=3, n_estimators=250, scaler=QuantileTransformer(n_quantiles=38), tau=0.2)\n",
        "\n",
        "  model.fit(xtrain, ytrain)\n",
        "  output = model.predict(xtest)\n",
        "\n",
        "  mse_gd.append(mse(ytest,output))\n",
        "\n",
        "print(\"MSE for GradientBoosting\")\n",
        "print(np.mean(mse_gd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfZQTvkGN_E_",
        "outputId": "ae2bdf8d-1008-4de0-d83b-859106945076"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE for GradientBoosting\n",
            "31.012359652900688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examples of Hyperparam Tuning"
      ],
      "metadata": {
        "id": "4olCBcv2Ojg9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a summary of the tuning I did. It started getting messy so this is a cleaned up version demonstrating the effects of the different hyperparameters."
      ],
      "metadata": {
        "id": "mjEvnxl0PtGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Effect Of Different scaler types"
      ],
      "metadata": {
        "id": "DbCULWKROpVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse_gd = []\n",
        "kf = KFold(n_splits=10,shuffle=True,random_state=1234)\n",
        "\n",
        "scalers = [MinMaxScaler(),StandardScaler(),QuantileTransformer(n_quantiles=39)]\n",
        "\n",
        "hyperparams = dict()\n",
        "for scaler in scalers:\n",
        "    mse_gd = []\n",
        "    for idxtrain, idxtest in kf.split(x):\n",
        "      xtrain = x[idxtrain]\n",
        "      ytrain = y[idxtrain]\n",
        "      ytest = y[idxtest]\n",
        "      xtest = x[idxtest]\n",
        "\n",
        "      model = GradientBoosting_LOWESS(xtrain, ytrain, num_steps=3, n_estimators=250, scaler=scaler, tau=0.2)\n",
        "\n",
        "      model.fit(xtrain, ytrain)\n",
        "      output = model.predict(xtest)\n",
        "\n",
        "      mse_gd.append(mse(ytest,output))\n",
        "\n",
        "    print(\"Scaler: \" + str(scaler))\n",
        "    print(\"Average MSE across KFolds: \", np.mean(mse_gd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu-N_SKQOqkj",
        "outputId": "538fd690-1a81-40e7-9871-5e8a030875a8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaler: MinMaxScaler()\n",
            "Average MSE across KFolds:  44.18563060176424\n",
            "Scaler: StandardScaler()\n",
            "Average MSE across KFolds:  133.7455194065987\n",
            "Scaler: QuantileTransformer(n_quantiles=39)\n",
            "Average MSE across KFolds:  31.26649405991544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Effect of different numbers of quantiles"
      ],
      "metadata": {
        "id": "w-jz9BrkPd01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse_gd = []\n",
        "kf = KFold(n_splits=10,shuffle=True,random_state=1234)\n",
        "\n",
        "quantiles = [10,20,30,40,50,60,70,80,90,100]\n",
        "\n",
        "hyperparams = dict()\n",
        "for quantile in quantiles:\n",
        "    mse_gd = []\n",
        "    for idxtrain, idxtest in kf.split(x):\n",
        "      xtrain = x[idxtrain]\n",
        "      ytrain = y[idxtrain]\n",
        "      ytest = y[idxtest]\n",
        "      xtest = x[idxtest]\n",
        "\n",
        "      model = GradientBoosting_LOWESS(xtrain, ytrain, num_steps=3, scaler=QuantileTransformer(n_quantiles=quantile), tau=0.2)\n",
        "\n",
        "      model.fit(xtrain, ytrain)\n",
        "      output = model.predict(xtest)\n",
        "\n",
        "      mse_gd.append(mse(ytest,output))\n",
        "\n",
        "    print(\"Quantile #: \" + str(quantile))\n",
        "    print(\"Average MSE across KFolds: \", np.mean(mse_gd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y85_4B-sPROm",
        "outputId": "a2c3b373-75a4-4973-e955-4eeb6abed0f1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantile #: 10\n",
            "Average MSE across KFolds:  31.895061550653175\n",
            "Quantile #: 20\n",
            "Average MSE across KFolds:  31.367150675377985\n",
            "Quantile #: 30\n",
            "Average MSE across KFolds:  31.1919539540773\n",
            "Quantile #: 40\n",
            "Average MSE across KFolds:  31.978771450104052\n",
            "Quantile #: 50\n",
            "Average MSE across KFolds:  31.780451181835712\n",
            "Quantile #: 60\n",
            "Average MSE across KFolds:  31.26475397016718\n",
            "Quantile #: 70\n",
            "Average MSE across KFolds:  31.539284454380144\n",
            "Quantile #: 80\n",
            "Average MSE across KFolds:  32.206149644466294\n",
            "Quantile #: 90\n",
            "Average MSE across KFolds:  31.16484862685557\n",
            "Quantile #: 100\n",
            "Average MSE across KFolds:  31.516660572901692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Effect of different taus"
      ],
      "metadata": {
        "id": "XkQCGcvHQLBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse_gd = []\n",
        "kf = KFold(n_splits=10,shuffle=True,random_state=1234)\n",
        "\n",
        "taus = [.1,.2,.3,.4,.5,.6,.7,.8,.9, 1.0]\n",
        "hyperparams = dict()\n",
        "for tau in tqdm(taus):\n",
        "    mse_gd = []\n",
        "    for idxtrain, idxtest in kf.split(x):\n",
        "      xtrain = x[idxtrain]\n",
        "      ytrain = y[idxtrain]\n",
        "      ytest = y[idxtest]\n",
        "      xtest = x[idxtest]\n",
        "\n",
        "      model = GradientBoosting_LOWESS(xtrain, ytrain, max_depth=7, num_steps=3, n_estimators=250, scaler=QuantileTransformer(n_quantiles=38), tau=tau)\n",
        "\n",
        "      model.fit(xtrain, ytrain)\n",
        "      output = model.predict(xtest)\n",
        "\n",
        "      mse_gd.append(mse(ytest,output))\n",
        "\n",
        "    print(\"Tau value: \" + str(tau))\n",
        "    print(\"Average MSE across KFolds: \", np.mean(mse_gd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4uFSNQFQJYr",
        "outputId": "dea0d25c-d8e6-4ede-a576-9d45f95be990"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [01:10<10:37, 70.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tau value: 0.1\n",
            "Average MSE across KFolds:  35.36241348359499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [02:22<09:29, 71.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tau value: 0.2\n",
            "Average MSE across KFolds:  31.309926744857552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [03:34<08:23, 71.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tau value: 0.3\n",
            "Average MSE across KFolds:  33.759599519821954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [04:46<07:09, 71.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tau value: 0.4\n",
            "Average MSE across KFolds:  33.46264606610201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [05:58<05:59, 71.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tau value: 0.5\n",
            "Average MSE across KFolds:  33.10789228951623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [07:09<04:46, 71.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tau value: 0.6\n",
            "Average MSE across KFolds:  32.75381779337831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [08:20<03:34, 71.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tau value: 0.7\n",
            "Average MSE across KFolds:  32.48706474716718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [09:32<02:23, 71.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tau value: 0.8\n",
            "Average MSE across KFolds:  32.46664821219609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [10:42<01:11, 71.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tau value: 0.9\n",
            "Average MSE across KFolds:  32.48652291387075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [11:52<00:00, 71.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tau value: 1.0\n",
            "Average MSE across KFolds:  32.42022146276115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2:"
      ],
      "metadata": {
        "id": "eJL95S3pi3GC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example of KNN Regression Class w/ uSearch"
      ],
      "metadata": {
        "id": "IgIW1jAYi6cC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from usearch.index import search, MetricKind, Matches, BatchMatches"
      ],
      "metadata": {
        "id": "arGap9Tai5qB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install usearch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxkrNOXwi-rA",
        "outputId": "25f22eb2-1f3e-452b-f799-7608816785d2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting usearch\n",
            "  Downloading usearch-2.9.0-cp310-cp310-manylinux_2_28_x86_64.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from usearch) (1.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from usearch) (4.66.2)\n",
            "Installing collected packages: usearch\n",
            "Successfully installed usearch-2.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class KNN_Regression:\n",
        "  def __init__(self, k=2):\n",
        "    self._k = k\n",
        "\n",
        "  def fit (self, x, y):\n",
        "    self.xtrain_ = x\n",
        "    self.ytrain_ = y\n",
        "\n",
        "  def predict(self, x_new):\n",
        "    check_is_fitted(self)\n",
        "    x = self.xtrain_\n",
        "    y = self.ytrain_\n",
        "\n",
        "    # For each observation in x_new, find its closest neighbors via uSearch Matches\n",
        "    # Subset the training data to only the n closest neighbors (number of neighbors)\n",
        "    # Train a Ridge model on this subset of data\n",
        "    # The prediction for this observation is the prediction of this Ridge model\n",
        "    if np.isscalar(x_new):\n",
        "      lm = linear_model.Ridge(alpha=0.02)\n",
        "      one_in_many: Matches = search(xtrain, x_new, self._k, MetricKind.L2sq, exact=True)\n",
        "      nearest_x = xtrain[one_in_many.keys]\n",
        "      nearest_y = ytrain[one_in_many.keys]\n",
        "      lm.fit(nearest_x, nearest_y)\n",
        "      return lm.predict(x_new.reshape(1,-1))\n",
        "    else:\n",
        "      y_est = []\n",
        "      for vector in x_new:\n",
        "        lm = linear_model.Ridge(alpha=0.02)\n",
        "        one_in_many: Matches = search(xtrain, vector, self._k, MetricKind.L2sq, exact=True)\n",
        "        nearest_x = x[one_in_many.keys]\n",
        "        nearest_y = y[one_in_many.keys]\n",
        "        lm.fit(nearest_x, nearest_y)\n",
        "        pred = lm.predict(vector.reshape(1,-1))\n",
        "        y_est.append(pred)\n",
        "      return y_est\n"
      ],
      "metadata": {
        "id": "5S5qGsoJi9lm"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = QuantileTransformer(n_quantiles=30)\n",
        "kf = KFold(n_splits=10,shuffle=True,random_state=1234)\n",
        "k_vals = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
        "\n",
        "for k_val in k_vals:\n",
        "  mse_k = []\n",
        "  for idxtrain, idxtest in kf.split(x):\n",
        "    xtrain = x[idxtrain]\n",
        "    ytrain = y[idxtrain]\n",
        "    ytest = y[idxtest]\n",
        "    xtest = x[idxtest]\n",
        "    xtrain = scaler.fit_transform(xtrain)\n",
        "    xtest = scaler.transform(xtest)\n",
        "\n",
        "    model = KNN_Regression(k=k_val)\n",
        "    model.fit(xtrain, ytrain)\n",
        "    output = model.predict(xtest)\n",
        "    mse_k.append(mse(ytest,output))\n",
        "\n",
        "  print(\"The current number of neighbors is \", k_val)\n",
        "  print(\"Average MSE across KFolds: \", np.mean(mse_k))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0atUH7PjlSl",
        "outputId": "386fe64a-e115-4c33-8c00-de7e697adc9e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current number of neighbors is  1\n",
            "Average MSE across KFolds:  45.03599980582525\n",
            "The current number of neighbors is  2\n",
            "Average MSE across KFolds:  32.241090652921365\n",
            "The current number of neighbors is  3\n",
            "Average MSE across KFolds:  27.24198118112987\n",
            "The current number of neighbors is  4\n",
            "Average MSE across KFolds:  26.365188572902678\n",
            "The current number of neighbors is  5\n",
            "Average MSE across KFolds:  24.848138331403526\n",
            "The current number of neighbors is  6\n",
            "Average MSE across KFolds:  23.903780929707043\n",
            "The current number of neighbors is  7\n",
            "Average MSE across KFolds:  23.95452595592333\n",
            "The current number of neighbors is  8\n",
            "Average MSE across KFolds:  23.529809835269877\n",
            "The current number of neighbors is  9\n",
            "Average MSE across KFolds:  23.3055924114512\n",
            "The current number of neighbors is  10\n",
            "Average MSE across KFolds:  23.2065687892969\n",
            "The current number of neighbors is  11\n",
            "Average MSE across KFolds:  23.511165788647208\n",
            "The current number of neighbors is  12\n",
            "Average MSE across KFolds:  23.43808459833049\n",
            "The current number of neighbors is  13\n",
            "Average MSE across KFolds:  24.390809522780813\n",
            "The current number of neighbors is  14\n",
            "Average MSE across KFolds:  24.993398839524183\n",
            "The current number of neighbors is  15\n",
            "Average MSE across KFolds:  24.713810539545065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W6QCbGVskBaY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H6A4Hk-omLav"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_absolute_error as mae, mean_squared_error as mse, r2_score as R2\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cpu\")\n",
        "dtype = torch.double"
      ],
      "metadata": {
        "id": "jcaqBhIMmTWh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# #1) SCAD PyTorch Class"
      ],
      "metadata": {
        "id": "OQUTV0WLnII2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation"
      ],
      "metadata": {
        "id": "JSfrnRfwnV7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SCAD(nn.Module):\n",
        "    def __init__(self, input_size, alpha=3.7, lambda_val=0.5):\n",
        "      '''\n",
        "      Initialize the SCAD Regression Model.\n",
        "      Default values are derived from JSTOR paper example.\n",
        "      Args:\n",
        "        - input_size (int) : Number of input features.\n",
        "        - alpha (float) : Hyperparameter that determines how quickly penalty declines as B increases\n",
        "        - lambda_val (float) : Hyperparam that determines B value threshold limits and corresponding penalty\n",
        "      '''\n",
        "      # Initializing the parent class\n",
        "      super(SCAD, self).__init__()\n",
        "      # Assigning params\n",
        "      self.input_size = input_size\n",
        "      self.alpha = alpha\n",
        "      self.lambda_val = lambda_val\n",
        "      # Defining linear regression layer w/o bias\n",
        "      self.linear = nn.Linear(input_size, 1, bias=False, device=device, dtype=dtype)\n",
        "\n",
        "      # Linear combination of the feature values\n",
        "      # Compute the linear combination for a given set of weights\n",
        "    def forward(self, x):\n",
        "      '''\n",
        "      Forward pass of the SCAD model.\n",
        "\n",
        "      Args:\n",
        "        x (Tensor): Input data with shape (batch_size, input_size)/\n",
        "\n",
        "      Returns:\n",
        "        Tensor: Predicted values with shape (batch_size, 1).\n",
        "      '''\n",
        "      # Do the linear combination\n",
        "      return self.linear(x)\n",
        "\n",
        "    def loss(self, y_pred, y_true):\n",
        "      '''\n",
        "      Compute the SCAD loss function\n",
        "\n",
        "      Args:\n",
        "        y_pred (Tensor): Predicted values with shape (batch_size, 1).\n",
        "        y_true (Tensor): True target values with shape (batch_size, 1).\n",
        "\n",
        "      Returns:\n",
        "        Tensor: The SCAD Loss.\n",
        "      '''\n",
        "\n",
        "      # Baseline MSE to add additional penalties to\n",
        "      mse_loss = nn.MSELoss()(y_pred, y_true)\n",
        "\n",
        "      weights = self.linear.weight\n",
        "\n",
        "      # Referencing https://andrewcharlesjones.github.io/journal/scad.html\n",
        "      # Depending on the values of the weights in regards to alpha and lambda, determine their associated penalties\n",
        "      is_linear = (torch.abs(weights) <= self.lambda_val)\n",
        "      is_quadratic = torch.logical_and(self.lambda_val < torch.abs(weights), torch.abs(weights) <= self.alpha * self.lambda_val)\n",
        "      is_constant = (self.alpha * self.lambda_val) < torch.abs(weights)\n",
        "\n",
        "      linear_part = (self.lambda_val * torch.abs(weights) * is_linear).sum()\n",
        "      quadratic_part = ((2 * self.alpha * self.lambda_val * torch.abs(weights) - weights**2 - self.lambda_val**2) / (2 * (self.alpha - 1)) * is_quadratic).sum()\n",
        "      constant_part = ((self.lambda_val**2 * (self.alpha + 1)) / 2 * is_constant).sum()\n",
        "\n",
        "      # The sum of the MSE + SCAD weight penalties\n",
        "      return mse_loss + linear_part + quadratic_part + constant_part\n",
        "\n",
        "\n",
        "    def fit(self, X, y, num_epochs=100, learning_rate=0.001):\n",
        "      '''\n",
        "      Fit the SCAD model to the training data.\n",
        "\n",
        "      Args:\n",
        "        X (Tensor): Input data w/ shape (num_samples, input_size).\n",
        "        y (Tensor): Target values with shape (num_samples, 1).\n",
        "        num_epochs (int): Number of training epochs.\n",
        "        learning_rate (float): Learning rate for optimization.\n",
        "      '''\n",
        "      optimizer = optim.SGD(self.parameters(), lr=learning_rate)\n",
        "      # Instead of SGD you could use Adaptive Descent => optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "      for epoch in range(num_epochs):\n",
        "          self.train()\n",
        "          optimizer.zero_grad()\n",
        "          y_pred = self(X)\n",
        "          # Prevent number contam\n",
        "          loss = self.loss(y_pred.flatten(), y.flatten())\n",
        "          # Updating the weights in the direction of the negative gradient w/ optimizer\n",
        "          # Compute new gradient\n",
        "          loss.backward()\n",
        "          # Update weights in direction of negative gradient\n",
        "          optimizer.step()\n",
        "\n",
        "          if (epoch + 1) % 1000 == 0:\n",
        "              print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "      \"\"\"\n",
        "      Predict target values for input data.\n",
        "\n",
        "      Args:\n",
        "        X (Tensor): Input data w/ shape (num_samples, input_size).\n",
        "\n",
        "      Returns:\n",
        "        Tensor: Predicted values w/ shape (num_samples, 1).\n",
        "      \"\"\"\n",
        "      self.eval()\n",
        "      with torch.no_grad():\n",
        "        y_pred = self(X)\n",
        "      return y_pred\n",
        "\n",
        "    def get_coefficients(self):\n",
        "        \"\"\"\n",
        "        Get the coefficients (weights) of the linear regression layer.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Coefficients with shape (output_size, input_size).\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        return self.linear.weight\n"
      ],
      "metadata": {
        "id": "Eb4DvrZ2mUuF"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation With real data & Variable Selection"
      ],
      "metadata": {
        "id": "Wx33VzplnbV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold\n",
        "scaler = MinMaxScaler()"
      ],
      "metadata": {
        "id": "GLdjuHLumlg5"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running with real data (concrete dataset)"
      ],
      "metadata": {
        "id": "wk3WiJ0Hv-x9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/ML2023/data/concrete.csv')\n",
        "x = data.drop(columns=['strength']).values\n",
        "y = data[\"strength\"].values\n",
        "x = scaler.fit_transform(x)\n",
        "x_torch = torch.tensor(x, device=device)\n",
        "y_torch = torch.tensor(y, device=device)\n",
        "model_scad = SCAD(input_size=x_torch.shape[1], alpha=3.7, lambda_val=0.5)\n",
        "model_scad.fit(x_torch, y_torch, num_epochs=10000, learning_rate=0.03)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bmIEywTnFuL",
        "outputId": "3aeec277-3e2f-49a3-c45b-7e96e2ac9745"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1000/10000], Loss: 119.90800985910722\n",
            "Epoch [2000/10000], Loss: 114.37446939086723\n",
            "Epoch [3000/10000], Loss: 112.92896028077199\n",
            "Epoch [4000/10000], Loss: 112.34706227375979\n",
            "Epoch [5000/10000], Loss: 112.09798192997035\n",
            "Epoch [6000/10000], Loss: 111.99058176163291\n",
            "Epoch [7000/10000], Loss: 111.94423300190888\n",
            "Epoch [8000/10000], Loss: 111.92422914485218\n",
            "Epoch [9000/10000], Loss: 111.91559549815906\n",
            "Epoch [10000/10000], Loss: 111.9118692191612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variable Selection"
      ],
      "metadata": {
        "id": "YuIBttMYunQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_scad.get_coefficients()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHOkaDBVtl1x",
        "outputId": "3322d887-a04e-4221-f50f-c918497d2741"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 51.1523,  36.0417,  16.7259, -20.0369,   9.5241,   5.2548,   6.5980,\n",
              "          41.4736]], dtype=torch.float64, requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "F834khIbuQtZ",
        "outputId": "e500a0a2-3617-4d47-feb7-867f9c15f3c7"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   cement   slag  ash  water  superplastic  coarseagg  fineagg  age  strength\n",
              "0   540.0    0.0  0.0  162.0           2.5     1040.0    676.0   28     79.99\n",
              "1   540.0    0.0  0.0  162.0           2.5     1055.0    676.0   28     61.89\n",
              "2   332.5  142.5  0.0  228.0           0.0      932.0    594.0  270     40.27\n",
              "3   332.5  142.5  0.0  228.0           0.0      932.0    594.0  365     41.05\n",
              "4   198.6  132.4  0.0  192.0           0.0      978.4    825.5  360     44.30"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14346c11-aeb6-4100-a407-86059aafaedb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cement</th>\n",
              "      <th>slag</th>\n",
              "      <th>ash</th>\n",
              "      <th>water</th>\n",
              "      <th>superplastic</th>\n",
              "      <th>coarseagg</th>\n",
              "      <th>fineagg</th>\n",
              "      <th>age</th>\n",
              "      <th>strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>79.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1055.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>61.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>270</td>\n",
              "      <td>40.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>365</td>\n",
              "      <td>41.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198.6</td>\n",
              "      <td>132.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978.4</td>\n",
              "      <td>825.5</td>\n",
              "      <td>360</td>\n",
              "      <td>44.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14346c11-aeb6-4100-a407-86059aafaedb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-14346c11-aeb6-4100-a407-86059aafaedb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-14346c11-aeb6-4100-a407-86059aafaedb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-009e62f3-179c-4534-89c0-f4b638cf981f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-009e62f3-179c-4534-89c0-f4b638cf981f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-009e62f3-179c-4534-89c0-f4b638cf981f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 1030,\n  \"fields\": [\n    {\n      \"column\": \"cement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 104.50636449481532,\n        \"min\": 102.0,\n        \"max\": 540.0,\n        \"num_unique_values\": 278,\n        \"samples\": [\n          337.9,\n          290.2,\n          262.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 86.27934174810584,\n        \"min\": 0.0,\n        \"max\": 359.4,\n        \"num_unique_values\": 185,\n        \"samples\": [\n          94.7,\n          119.0,\n          136.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ash\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63.99700415268765,\n        \"min\": 0.0,\n        \"max\": 200.1,\n        \"num_unique_values\": 156,\n        \"samples\": [\n          98.0,\n          142.0,\n          195.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"water\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.35421856503247,\n        \"min\": 121.8,\n        \"max\": 247.0,\n        \"num_unique_values\": 195,\n        \"samples\": [\n          195.4,\n          183.8,\n          127.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"superplastic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.97384139248552,\n        \"min\": 0.0,\n        \"max\": 32.2,\n        \"num_unique_values\": 111,\n        \"samples\": [\n          15.0,\n          28.2,\n          16.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"coarseagg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 77.75395396672077,\n        \"min\": 801.0,\n        \"max\": 1145.0,\n        \"num_unique_values\": 284,\n        \"samples\": [\n          852.1,\n          913.9,\n          914.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fineagg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.17598014240437,\n        \"min\": 594.0,\n        \"max\": 992.6,\n        \"num_unique_values\": 302,\n        \"samples\": [\n          710.0,\n          695.4,\n          769.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63,\n        \"min\": 1,\n        \"max\": 365,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          91,\n          100,\n          28\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"strength\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.705741961912512,\n        \"min\": 2.33,\n        \"max\": 82.6,\n        \"num_unique_values\": 845,\n        \"samples\": [\n          41.68,\n          39.59,\n          2.33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the $\\beta$ values that have the highest weights, SCAD has determined that $X_0$, $X_1$ and $X_7$ are the features with the greatest importance in determining cement strength. These features are respectively, the cement value, the slag value and the age value."
      ],
      "metadata": {
        "id": "e0EGdnM7t01o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/ML2023/data/concrete.csv')\n",
        "x = data.drop(columns=['strength']).values\n",
        "y = data[\"strength\"].values\n",
        "x = scaler.fit_transform(x)\n",
        "x_torch = torch.tensor(x, device=device)\n",
        "y_torch = torch.tensor(y, device=device)\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_torch, y_torch, test_size=0.33, random_state=42)\n",
        "model_scad = SCAD(input_size=X_train.shape[1], alpha=3.7, lambda_val=0.5)\n",
        "model_scad.fit(X_train, y_train, num_epochs=10000, learning_rate=0.03)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCr6NuEmzGog",
        "outputId": "722ca6aa-a68b-4a75-8834-8b8b62ec0782"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1000/10000], Loss: 117.94888529616418\n",
            "Epoch [2000/10000], Loss: 112.77649898280517\n",
            "Epoch [3000/10000], Loss: 111.5353512831315\n",
            "Epoch [4000/10000], Loss: 111.05189130080291\n",
            "Epoch [5000/10000], Loss: 110.84769117344678\n",
            "Epoch [6000/10000], Loss: 110.76049540917815\n",
            "Epoch [7000/10000], Loss: 110.7232091532624\n",
            "Epoch [8000/10000], Loss: 110.7072620732839\n",
            "Epoch [9000/10000], Loss: 110.70044145527584\n",
            "Epoch [10000/10000], Loss: 110.69752424598259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse(model_scad.predict(X_test), y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBp-3zGNzIOP",
        "outputId": "9702ab78-1747-45b8-e692-fb9982ab3fef"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "111.69770283817272"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ElasticNet comparision"
      ],
      "metadata": {
        "id": "HgfnQ_Ox0DEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ElasticNet(nn.Module):\n",
        "    def __init__(self, input_size, alpha=1.0, l1_ratio=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the ElasticNet regression model.\n",
        "\n",
        "        Args:\n",
        "            input_size (int): Number of input features.\n",
        "            alpha (float): Regularization strength. Higher values of alpha\n",
        "                emphasize L1 regularization, while lower values emphasize L2 regularization.\n",
        "            l1_ratio (float): The ratio of L1 regularization to the total\n",
        "                regularization (L1 + L2). It should be between 0 and 1.\n",
        "\n",
        "        \"\"\"\n",
        "        super(ElasticNet, self).__init__()\n",
        "        # nueron needs to know input size => the number of features you have\n",
        "        # e.g num of pixels you have\n",
        "        self.input_size = input_size\n",
        "        self.alpha = alpha\n",
        "        self.l1_ratio = l1_ratio\n",
        "\n",
        "        # Define the linear regression layer\n",
        "        # ,1 means deal w/ it as 1d area, double() => as double precision\n",
        "        self.linear = nn.Linear(input_size, 1).double()\n",
        "        # Forces neuron to ignore the bias - handle intercept term seperately\n",
        "        # Best practice\n",
        "        self.linear = nn.Linear(input_size, 1, bias=False, device=device, dtype=dtype)\n",
        "\n",
        "    # Linear combination of the feature values\n",
        "    # Compute the linear combination for a given set of weights\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the ElasticNet model.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input data with shape (batch_size, input_size).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Predicted values with shape (batch_size, 1).\n",
        "\n",
        "        \"\"\"\n",
        "        # Do the linear combinations according to this specific combination\n",
        "        return self.linear(x)\n",
        "\n",
        "    def loss(self, y_pred, y_true):\n",
        "        \"\"\"\n",
        "        Compute the ElasticNet loss function.\n",
        "\n",
        "        Args:\n",
        "            y_pred (Tensor): Predicted values with shape (batch_size, 1).\n",
        "            y_true (Tensor): True target values with shape (batch_size, 1).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: The ElasticNet loss.\n",
        "\n",
        "        \"\"\"\n",
        "        mse_loss = nn.MSELoss()(y_pred, y_true)\n",
        "        # Lasso\n",
        "        l1_reg = torch.norm(self.linear.weight, p=1)\n",
        "        # Ridge\n",
        "        l2_reg = torch.norm(self.linear.weight, p=2)\n",
        "\n",
        "        loss = 0.5*mse_loss + self.alpha * (\n",
        "            0.5*self.l1_ratio * l1_reg + (1 - self.l1_ratio) * (1/2)*l2_reg**2\n",
        "        )\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def fit(self, X, y, num_epochs=100, learning_rate=0.01):\n",
        "        \"\"\"\n",
        "        Fit the ElasticNet model to the training data.\n",
        "\n",
        "        Args:\n",
        "            X (Tensor): Input data with shape (num_samples, input_size).\n",
        "            y (Tensor): Target values with shape (num_samples, 1).\n",
        "            num_epochs (int): Number of training epochs.\n",
        "            learning_rate (float): Learning rate for optimization.\n",
        "\n",
        "        \"\"\"\n",
        "        optimizer = optim.SGD(self.parameters(), lr=learning_rate)\n",
        "        # Instead of SGD you could use Adaptive Descent => optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            self.train()\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = self(X)\n",
        "            # Prevent number contam\n",
        "            loss = self.loss(y_pred.flatten(), y.flatten())\n",
        "            # Updating the weights in the direction of the negative gradient w/ optimizer\n",
        "            # Compute new gradient\n",
        "            loss.backward()\n",
        "            # Update weights in direction of negative gradient\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict target values for input data.\n",
        "\n",
        "        Args:\n",
        "            X (Tensor): Input data with shape (num_samples, input_size).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Predicted values with shape (num_samples, 1).\n",
        "\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = self(X)\n",
        "        return y_pred\n",
        "    def get_coefficients(self):\n",
        "        \"\"\"\n",
        "        Get the coefficients (weights) of the linear regression layer.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Coefficients with shape (output_size, input_size).\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # Each class has helpful items\n",
        "        return self.linear.weight\n"
      ],
      "metadata": {
        "id": "Jr_T1p0TziO-"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/ML2023/data/concrete.csv')\n",
        "x = data.drop(columns=['strength']).values\n",
        "y = data[\"strength\"].values\n",
        "x = scaler.fit_transform(x)\n",
        "x_torch = torch.tensor(x, device=device)\n",
        "y_torch = torch.tensor(y, device=device)\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_torch, y_torch, test_size=0.33, random_state=42)\n",
        "model_e = ElasticNet(input_size=X_train.shape[1])\n",
        "model_e.fit(X_train, y_train, num_epochs=10000, learning_rate=0.001)"
      ],
      "metadata": {
        "id": "MoSGjsPTzVlI"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse(model_e.predict(X_test), y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28fXdLV6zltV",
        "outputId": "d77b956e-2c17-4de9-e071-c8b70d022b2f"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "374.1414255710245"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Betastar Simulations"
      ],
      "metadata": {
        "id": "wT7fFjXAuzBb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functionality to make correlated dataset"
      ],
      "metadata": {
        "id": "IJXc7i92vTl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import toeplitz"
      ],
      "metadata": {
        "id": "wvQWuRuovGmb"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From lecture \"Variable selection and regularization\"\n",
        "def make_correlated_features(num_samples,p,rho):\n",
        "  vcor = []\n",
        "  for i in range(p):\n",
        "    vcor.append(rho**i)\n",
        "  r = toeplitz(vcor)\n",
        "  mu = np.repeat(0,p)\n",
        "  # mu vector of the means\n",
        "  x = np.random.multivariate_normal(mu, r, size=num_samples)\n",
        "  return x\n",
        "\n",
        "def make_correlated_dataset():\n",
        "  rho =0.9\n",
        "  p = 200\n",
        "  n = 150\n",
        "\n",
        "  x = make_correlated_features(n,p,rho)\n",
        "  # Simulating a sparsity pattern\n",
        "  beta =np.array([0,1,2,-3,0,0,0,1,4,2,0,1,-1])\n",
        "  # Making this sparsity pattern match the number of variables in X (filling in unused vars w/ 0)\n",
        "  beta = beta.reshape(-1,1)\n",
        "  betastar = np.concatenate([beta,np.repeat(0,p-len(beta)).reshape(-1,1)],axis=0)\n",
        "  # Creating a y which utilizes this sparsity pattern plus some random noise\n",
        "  y = x@betastar + 0.5*np.random.normal(size=(150,1))\n",
        "  return x,y"
      ],
      "metadata": {
        "id": "6IVKTilzu0ln"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining regressors without print statements"
      ],
      "metadata": {
        "id": "vQWIKg-_vWKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ElasticNet(nn.Module):\n",
        "    def __init__(self, input_size, alpha=1.0, l1_ratio=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the ElasticNet regression model.\n",
        "\n",
        "        Args:\n",
        "            input_size (int): Number of input features.\n",
        "            alpha (float): Regularization strength. Higher values of alpha\n",
        "                emphasize L1 regularization, while lower values emphasize L2 regularization.\n",
        "            l1_ratio (float): The ratio of L1 regularization to the total\n",
        "                regularization (L1 + L2). It should be between 0 and 1.\n",
        "\n",
        "        \"\"\"\n",
        "        super(ElasticNet, self).__init__()\n",
        "        # nueron needs to know input size => the number of features you have\n",
        "        # e.g num of pixels you have\n",
        "        self.input_size = input_size\n",
        "        self.alpha = alpha\n",
        "        self.l1_ratio = l1_ratio\n",
        "\n",
        "        # Define the linear regression layer\n",
        "        # ,1 means deal w/ it as 1d area, double() => as double precision\n",
        "        self.linear = nn.Linear(input_size, 1).double()\n",
        "        # Forces neuron to ignore the bias - handle intercept term seperately\n",
        "        # Best practice\n",
        "        self.linear = nn.Linear(input_size, 1, bias=False, device=device, dtype=dtype)\n",
        "\n",
        "    # Linear combination of the feature values\n",
        "    # Compute the linear combination for a given set of weights\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the ElasticNet model.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input data with shape (batch_size, input_size).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Predicted values with shape (batch_size, 1).\n",
        "\n",
        "        \"\"\"\n",
        "        # Do the linear combinations according to this specific combination\n",
        "        return self.linear(x)\n",
        "\n",
        "    def loss(self, y_pred, y_true):\n",
        "        \"\"\"\n",
        "        Compute the ElasticNet loss function.\n",
        "\n",
        "        Args:\n",
        "            y_pred (Tensor): Predicted values with shape (batch_size, 1).\n",
        "            y_true (Tensor): True target values with shape (batch_size, 1).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: The ElasticNet loss.\n",
        "\n",
        "        \"\"\"\n",
        "        mse_loss = nn.MSELoss()(y_pred, y_true)\n",
        "        # Lasso\n",
        "        l1_reg = torch.norm(self.linear.weight, p=1)\n",
        "        # Ridge\n",
        "        l2_reg = torch.norm(self.linear.weight, p=2)\n",
        "\n",
        "        loss = 0.5*mse_loss + self.alpha * (\n",
        "            0.5*self.l1_ratio * l1_reg + (1 - self.l1_ratio) * (1/2)*l2_reg**2\n",
        "        )\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def fit(self, X, y, num_epochs=100, learning_rate=0.01):\n",
        "        \"\"\"\n",
        "        Fit the ElasticNet model to the training data.\n",
        "\n",
        "        Args:\n",
        "            X (Tensor): Input data with shape (num_samples, input_size).\n",
        "            y (Tensor): Target values with shape (num_samples, 1).\n",
        "            num_epochs (int): Number of training epochs.\n",
        "            learning_rate (float): Learning rate for optimization.\n",
        "\n",
        "        \"\"\"\n",
        "        optimizer = optim.SGD(self.parameters(), lr=learning_rate)\n",
        "        # Instead of SGD you could use Adaptive Descent => optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            self.train()\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = self(X)\n",
        "            # Prevent number contam\n",
        "            loss = self.loss(y_pred, y)\n",
        "            # Updating the weights in the direction of the negative gradient w/ optimizer\n",
        "            # Compute new gradient\n",
        "            loss.backward()\n",
        "            # Update weights in direction of negative gradient\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict target values for input data.\n",
        "\n",
        "        Args:\n",
        "            X (Tensor): Input data with shape (num_samples, input_size).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Predicted values with shape (num_samples, 1).\n",
        "\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = self(X)\n",
        "        return y_pred\n",
        "    def get_coefficients(self):\n",
        "        \"\"\"\n",
        "        Get the coefficients (weights) of the linear regression layer.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Coefficients with shape (output_size, input_size).\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # Each class has helpful items\n",
        "        return self.linear.weight\n"
      ],
      "metadata": {
        "id": "1w7HWmy-wG5Y"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From lecture\n",
        "# we can call this version PED_Adam because we use the adaptive momentum gradient descent for optimization\n",
        "class sqrtLasso(nn.Module):\n",
        "    def __init__(self, input_size, alpha=0.1):\n",
        "        \"\"\"\n",
        "        Initialize the  regression model.\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        super(sqrtLasso, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.alpha = alpha\n",
        "\n",
        "\n",
        "        # Define the linear regression layer\n",
        "        self.linear = nn.Linear(input_size, 1).double()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input data with shape (batch_size, input_size).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Predicted values with shape (batch_size, 1).\n",
        "\n",
        "        \"\"\"\n",
        "        return self.linear(x)\n",
        "\n",
        "    def loss(self, y_pred, y_true):\n",
        "        \"\"\"\n",
        "        Compute the loss function.\n",
        "\n",
        "        Args:\n",
        "            y_pred (Tensor): Predicted values with shape (batch_size, 1).\n",
        "            y_true (Tensor): True target values with shape (batch_size, 1).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: The loss.\n",
        "\n",
        "        \"\"\"\n",
        "        mse_loss = nn.MSELoss()(y_pred, y_true)\n",
        "        l1_reg = torch.norm(self.linear.weight, p=1,dtype=torch.float64)\n",
        "        # l2_reg = torch.norm(self.linear.weight, p=2,dtype=torch.float64)\n",
        "\n",
        "        loss = (len(y_true)*mse_loss)**(1/2) + self.alpha * (l1_reg)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def fit(self, X, y, num_epochs=200, learning_rate=0.01):\n",
        "        \"\"\"\n",
        "        Fit the model to the training data.\n",
        "\n",
        "        Args:\n",
        "            X (Tensor): Input data with shape (num_samples, input_size).\n",
        "            y (Tensor): Target values with shape (num_samples, 1).\n",
        "            num_epochs (int): Number of training epochs.\n",
        "            learning_rate (float): Learning rate for optimization.\n",
        "\n",
        "        \"\"\"\n",
        "        optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            self.train()\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = self(X)\n",
        "            loss = self.loss(y_pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict target values for input data.\n",
        "\n",
        "        Args:\n",
        "            X (Tensor): Input data with shape (num_samples, input_size).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Predicted values with shape (num_samples, 1).\n",
        "\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = self(X)\n",
        "        return y_pred\n",
        "    def get_coefficients(self):\n",
        "        \"\"\"\n",
        "        Get the coefficients (weights) of the linear regression layer.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Coefficients with shape (output_size, input_size).\n",
        "\n",
        "        \"\"\"\n",
        "        return self.linear.weight"
      ],
      "metadata": {
        "id": "AHkvyA75wKjH"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SCAD(nn.Module):\n",
        "    def __init__(self, input_size, alpha=3.7, lambda_val=0.5):\n",
        "      '''\n",
        "      Initialize the SCAD Regression Model.\n",
        "      Default values are derived from JSTOR paper example.\n",
        "      Args:\n",
        "        - input_size (int) : Number of input features.\n",
        "        - alpha (float) : Hyperparameter that determines how quickly penalty declines as B increases\n",
        "        - lambda_val (float) : Hyperparam that determines B value threshold limits and corresponding penalty\n",
        "      '''\n",
        "      # Initializing the parent class\n",
        "      super(SCAD, self).__init__()\n",
        "      # Assigning params\n",
        "      self.input_size = input_size\n",
        "      self.alpha = alpha\n",
        "      self.lambda_val = lambda_val\n",
        "      # Defining linear regression layer w/o bias\n",
        "      self.linear = nn.Linear(input_size, 1, bias=False, device=device, dtype=dtype)\n",
        "\n",
        "      # Linear combination of the feature values\n",
        "      # Compute the linear combination for a given set of weights\n",
        "    def forward(self, x):\n",
        "      '''\n",
        "      Forward pass of the SCAD model.\n",
        "\n",
        "      Args:\n",
        "        x (Tensor): Input data with shape (batch_size, input_size)/\n",
        "\n",
        "      Returns:\n",
        "        Tensor: Predicted values with shape (batch_size, 1).\n",
        "      '''\n",
        "      # Do the linear combination\n",
        "      return self.linear(x)\n",
        "\n",
        "    def loss(self, y_pred, y_true):\n",
        "      '''\n",
        "      Compute the SCAD loss function\n",
        "\n",
        "      Args:\n",
        "        y_pred (Tensor): Predicted values with shape (batch_size, 1).\n",
        "        y_true (Tensor): True target values with shape (batch_size, 1).\n",
        "\n",
        "      Returns:\n",
        "        Tensor: The SCAD Loss.\n",
        "      '''\n",
        "\n",
        "      mse_loss = nn.MSELoss()(y_pred, y_true)\n",
        "      weights = self.linear.weight\n",
        "\n",
        "      # Using\n",
        "      is_linear = (torch.abs(weights) <= self.lambda_val)\n",
        "      is_quadratic = torch.logical_and(self.lambda_val < torch.abs(weights), torch.abs(weights) <= self.alpha * self.lambda_val)\n",
        "      is_constant = (self.alpha * self.lambda_val) < torch.abs(weights)\n",
        "\n",
        "      linear_part = (self.lambda_val * torch.abs(weights) * is_linear).sum()\n",
        "      quadratic_part = ((2 * self.alpha * self.lambda_val * torch.abs(weights) - weights**2 - self.lambda_val**2) / (2 * (self.alpha - 1)) * is_quadratic).sum()\n",
        "      constant_part = ((self.lambda_val**2 * (self.alpha + 1)) / 2 * is_constant).sum()\n",
        "\n",
        "      return mse_loss + linear_part + quadratic_part + constant_part\n",
        "\n",
        "\n",
        "    def fit(self, X, y, num_epochs=100, learning_rate=0.001):\n",
        "      '''\n",
        "      Fit the SCAD model to the training data.\n",
        "\n",
        "      Args:\n",
        "        X (Tensor): Input data w/ shape (num_samples, input_size).\n",
        "        y (Tensor): Target values with shape (num_samples, 1).\n",
        "        num_epochs (int): Number of training epochs.\n",
        "        learning_rate (float): Learning rate for optimization.\n",
        "      '''\n",
        "      optimizer = optim.SGD(self.parameters(), lr=learning_rate)\n",
        "      # Instead of SGD you could use Adaptive Descent => optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "      for epoch in range(num_epochs):\n",
        "          self.train()\n",
        "          optimizer.zero_grad()\n",
        "          y_pred = self(X)\n",
        "          # Prevent number contam\n",
        "          loss = self.loss(y_pred.flatten(), y.flatten())\n",
        "          # Updating the weights in the direction of the negative gradient w/ optimizer\n",
        "          # Compute new gradient\n",
        "          loss.backward()\n",
        "          # Update weights in direction of negative gradient\n",
        "          optimizer.step()\n",
        "\n",
        "    def predict(self, X):\n",
        "      \"\"\"\n",
        "      Predict target values for input data.\n",
        "\n",
        "      Args:\n",
        "        X (Tensor): Input data w/ shape (num_samples, input_size).\n",
        "\n",
        "      Returns:\n",
        "        Tensor: Predicted values w/ shape (num_samples, 1).\n",
        "      \"\"\"\n",
        "      self.eval()\n",
        "      with torch.no_grad():\n",
        "        y_pred = self(X)\n",
        "      return y_pred\n",
        "\n",
        "    def get_coefficients(self):\n",
        "        \"\"\"\n",
        "        Get the coefficients (weights) of the linear regression layer.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Coefficients with shape (output_size, input_size).\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        return self.linear.weight\n"
      ],
      "metadata": {
        "id": "D5KB48zkwPUU"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "IomgBESAwPsc"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment"
      ],
      "metadata": {
        "id": "KobFtMfTwUN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = 200\n",
        "# Simulating a sparsity pattern\n",
        "beta =np.array([0,1,2,-3,0,0,0,1,4,2,0,1,-1])\n",
        "# Making this sparsity pattern match the number of variables in X (filling in unused vars w/ 0)\n",
        "beta = beta.reshape(-1,1)\n",
        "betastar = np.concatenate([beta,np.repeat(0,p-len(beta)).reshape(-1,1)],axis=0)"
      ],
      "metadata": {
        "id": "Xg7mrCewwwb_"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scad_difs = []\n",
        "elastic_difs = []\n",
        "sqrtlasso_difs = []\n",
        "\n",
        "for iter in tqdm(range(500)):\n",
        "  x,y = make_correlated_dataset()\n",
        "  x_scaled = scaler.fit_transform(x)\n",
        "  x_torch = torch.tensor(x_scaled, device=device)\n",
        "  y_torch = torch.tensor(y, device=device)\n",
        "  model_scad = SCAD(x_torch.shape[1])\n",
        "  model_elastic = ElasticNet(x_torch.shape[1])\n",
        "  model_sqrtlasso = sqrtLasso(x_torch.shape[1])\n",
        "\n",
        "  model_scad.fit(x_torch, y_torch)\n",
        "  model_elastic.fit(x_torch, y_torch)\n",
        "  model_sqrtlasso.fit(x_torch, y_torch)\n",
        "\n",
        "  scad_coefs = model_scad.get_coefficients().cpu().detach().numpy()\n",
        "  elastic_coefs = model_elastic.get_coefficients().cpu().detach().numpy()\n",
        "  sqrtlasso_coefs = model_sqrtlasso.get_coefficients().cpu().detach().numpy()\n",
        "\n",
        "  scad_difs.append(mse(betastar, scad_coefs.reshape(-1,1)))\n",
        "  elastic_difs.append(mse(betastar, elastic_coefs.reshape(-1,1)))\n",
        "  sqrtlasso_difs.append(mse(betastar, sqrtlasso_coefs.reshape(-1,1)))\n",
        "\n",
        "print(\" \")\n",
        "print(\"Mean scad MSE with regards to betastar is \", np.mean(scad_difs))\n",
        "print(\"Mean elastic MSE with regards to betastar is \", np.mean(elastic_difs))\n",
        "print(\"Mean sqrt lasso MSE with regards to betastar is \", np.mean(sqrtlasso_difs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHGgQgcFwU0k",
        "outputId": "3c67c5c1-1b0c-4fc2-c3ac-b46752c23eab"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [03:40<00:00,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "Mean scad MSE with regards to betastar is  0.17427232220926658\n",
            "Mean elastic MSE with regards to betastar is  0.15646798274095441\n",
            "Mean sqrt lasso MSE with regards to betastar is  0.4115441597152536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like generally ElasticNet produces the coefficients closest to Betastar, with SCAD closely following it, and SQRTLasso last."
      ],
      "metadata": {
        "id": "i1eLL7mAx3Hl"
      }
    }
  ]
}